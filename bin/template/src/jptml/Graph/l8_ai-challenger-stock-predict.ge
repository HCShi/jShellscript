[ 一: 数据预览 \
  DataFrame 一般预览数据的顺序 \n
  Matplotlib 查看各属性之间和 label 的关系; 放弃了, 属性太多了, 名字还一样 feature1-104, 没重点, 还是先用 logistic 跑一遍, 将相关系数小的筛掉 \n
  ] { flow: south } -->

[ 二: 数据预处理: 特征工程(feature engineering) \n
  二(1): 一开始的思路是用 Logistic 算出每个 feature 的权重, 将权重小的 pass; 后来太慢了, 最后放弃 \n
  feather1-104, 各属性基本都是 \[-10, 10\], 但也有特殊的情况, 进行 StandardScale 归一化 \n
  尝试了 StandardScale 和 MinMaxScaler , 发现后者更好用 \n
  linear_model.LogisticRegression.fit(X_scaled, y) 直接 fit, 没有交叉验证, 因为要看的只是各个属性的权重和 label 之间的关系 \n
  然后就花了 2h 来跑这个, 发现好像只用了 feather*, 忘加 group* 属性了, 没多大关系 \n
  最后 KeyboardInterrupt, 真的跟我没关系... \n
  换成 NB 来跑, 很快, 但是结果不是权重, 用不了 \n
  print(clf.feature_importances_); error: NB 没有 feature_importances_ \n
  \n
  二(2): 在 train 上 train_test_split, 看 NB 会有什么结果 \n
  print(np.mean(predicted == split_cv\[:, -1\]));  0.536583015072; 大于 0.5, 优化一下还可以吧 \n
  \n
  二(5): 使用 全连接神经网络测试, 调了各种属性的组合, 最后发现必须使用集成学习来进行了... \n
  模型在 mnist 二分类的数据集正确率 0.98, 在这个数据集上 0.56... \n
  遇到了神经网络解决不了的问题了 \n
  ] { flow: south } -->

[ 三: 建立模型 \n ] { flow: south } -->

[ 四: 交叉验证 \n ] { flow: south } -->

[ 五: 测试集处理 \n
  目前使用的是 二(2) 中的 NB 的 clf
  ] { flow: south } -->

[ 六: 模型优化 \n
  ] { flow: south } -->

[ 七: 交叉验证 \n
  ] { flow: south } -->

[ 八: 模型融合 \n
  ]
