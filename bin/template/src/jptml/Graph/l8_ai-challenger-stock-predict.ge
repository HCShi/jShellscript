[ 一: 数据预览 \
  DataFrame 一般预览数据的顺序 \n
  Matplotlib 查看各属性之间和 label 的关系; 放弃了, 属性太多了, 名字还一样 feature1-104, 没重点, 还是先用 logistic 跑一遍, 将相关系数小的筛掉 \n
  ] { flow: south } -->

[ 二: 数据预处理: 特征工程(feature engineering) \n
  二(1): 一开始的思路是用 Logistic 算出每个 feature 的权重, 将权重小的 pass; 后来太慢了, 最后放弃 \n
  feather1-104, 各属性基本都是 \[-10, 10\], 但也有特殊的情况, 进行 StandardScale 归一化 \n
  尝试了 StandardScale 和 MinMaxScaler , 发现后者更好用 \n
  linear_model.LogisticRegression.fit(X_scaled, y) 直接 fit, 没有交叉验证, 因为要看的只是各个属性的权重和 label 之间的关系 \n
  然后就花了 2h 来跑这个, 发现好像只用了 feather*, 忘加 group* 属性了, 没多大关系 \n
  最后 KeyboardInterrupt, 真的跟我没关系... \n
  换成 NB 来跑, 很快, 但是结果不是权重, 用不了 \n
  print(clf.feature_importances_); error: NB 没有 feature_importances_ \n
  \n
  二(2): 在 train 上 train_test_split, 看 NB 会有什么结果 \n
  print(np.mean(predicted == split_cv\[:, -1\]));  0.536583015072; 大于 0.5, 优化一下还可以吧 \n
  ] { flow: south } -->

[ 三: 建立模型 \n ] { flow: south } -->

[ 四: 交叉验证 \n ] { flow: south } -->

[ 五: 测试集处理 \n
  目前使用的是 二(2) 中的 NB 的 clf
  ] { flow: south } -->

[ 六: 模型优化 \n
  查看个属性的权重: \n
  print(pd.DataFrame({"columns": list(train_df.columns)\[1:\], "coef":list(clf.coef_.T)})) \n
  分析各属性的 正/负 相关性
  ] { flow: south } -->

[ 七: 交叉验证 \n
  进行一次训练集分割(train_test_split), 训练, 预测, 查看那些错误的样例: \n
  bad_cases = origin_data_train.loc\[origin_data_train\['PassengerId'\].isin(split_cv\[predictions != cv_df.as_matrix()\[:, 0\]\]\['PassengerId'\].values)\]
  ] { flow: south } -->

[ 八: 模型融合 \n
  两种融合方式: \n
  1. 使用多种模型进行 AdaBoost \n
  2. 将数据分块, 同一模型对不同数据块训练, 得到不同权重的模型 \n
  这里用的是第二种 ]
